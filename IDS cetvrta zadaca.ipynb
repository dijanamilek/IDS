{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30e9ce05",
   "metadata": {},
   "source": [
    "# Laboratory exercise 4\n",
    "\n",
    "In this laboratory exercise you will use the questionnaire and answers given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6820020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c53f916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionnaire = pd.DataFrame({'Q1': [1, 2, 2, 3, 2, 2, 3, 3, 2, 3],\n",
    "                              'Q2': [1, 1, 1, 2, 3, 3, 2, 3, 3, 3],\n",
    "                              'Q3': [1, 1, 2, 1, 2, 3, 3, 3, 2, 3]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc3ba1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionnaire.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce36a49d",
   "metadata": {},
   "source": [
    "1. Write a function to detrmine the realiability of the questionnaire answers with Cronbach's Alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abfbf831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cronbach_alpha(data):\n",
    "        # Calculate the number of items (variables):\n",
    "        num_data = data.shape[1]\n",
    "        # Calculates the total variance across all items for each respondent:\n",
    "        total_variance = np.var(data.sum(axis=1), ddof=num_data)\n",
    "        observed_variance = np.sum(data.var(axis=0, ddof=1))\n",
    "        \n",
    "        cronbach_alpha = (num_data / (num_data - 1)) * (1 - observed_variance / total_variance)\n",
    "        \n",
    "        return cronbach_alpha\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebe2f287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cronbach's Alpha:  0.9349\n"
     ]
    }
   ],
   "source": [
    "result = cronbach_alpha(questionnaire)\n",
    "\n",
    "print(f\"Cronbach's Alpha: {result: .4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cb9d0a",
   "metadata": {},
   "source": [
    "2. Explain the differences between in-house data labeling, crowdsourcing and outsourcing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc88e065",
   "metadata": {},
   "source": [
    "The choice of data labeling approach depends on various factors such as the nature of the problem, project timelines, and the available workforce. In-house data labeling, conducted by scientists or internal staff, ensures the highest quality but can be time-consuming especially when higher-quality tags are crucial, especially for tasks in fields like insurance or healthcare where correct labeling is of high priority. This approach also often requires consulting with experts in the field to correctly label the data.  Crowdsourcing involves a large number of freelancers on platforms, suitable for annotating simpler data like images of animals, plants, and natural environments. Outsourcing, positioned between in-house and crowdsourcing, allows tasks to be assigned to trained annotators or organizations, providing a middle ground for projects that require quality data labeling but may have budget constraints. Evaluation of individual annotators can be done before assigning tasks, making outsourcing a versatile option for projects with specific quality data marking and limited funding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3d3e91",
   "metadata": {},
   "source": [
    "3. Explain the main differences between annotation for image classification, object detection and image segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91110ddc",
   "metadata": {},
   "source": [
    "Image annotation is the process of categorizing or labeling an image using language and/or annotation tools in order to display the data features wanted for the model to automatically recognize. Image classification refers to the method of annotation that just **identifies** the presence of similar objects depicted in images across an entire dataset. In other words, image annotation refers to adding a tag to an image with the number of unique tags in the entire database is the number of\n",
    "classes that the model can classify.This is the most basic type of data annotation that simply identifies the presence of a given object, without specifying its position in the picture. In other words its purpose is to train a model to recognize the existence of an object across images with simple tagging, thereby often missing nuance and detail of the picture and oversimplifying it to a single label. Classification with multiple tags is also possible, in which case each image has more than one tag. The classification can be binary - meaning  that it consists of only two labels; or multi-class - in which case it contains several labels.  \n",
    "Object detection combines classification and localization to identify the objects present in an image or video and determine their respective locations within the image, i.e. it identifies both the object and its location. Each object is marked with a bounding box, a rectangle as small as possible around it which usually contains a label of the object. The rectangle's coordinates and the corresponding label are recorded and stored in a JSON file using a dictionary format, with the image's number or ID serving as the key within the dictionary. Object detection helps us define what is in the image, and where it is. But, it doesnâ€™t clearly define either the shape or size of the objects. One of the limits of this approach is that it is often harder for the model to recognize objects that may be positioned differently in the image than in the training data.\n",
    "Image segmentation is a more advanced type of data labeling. It includes dividing the image into different parts (segments).  This division of the image into segments allows one to dive deeper into what's happening in the image and understand how different objects in the image relate to each other. In other words, image segmentation separates image objects from their background and other objects in the image which usually results in images of the same size as the original image, containing 1 where the object is present and 0 otherwise (binary masks). In cases of multiple objects, each is marked on a separate channel, in which case the sum of all channels is the reference image.\n",
    "To conclude, image classification assigns class labels, object detection locates objects with bounding boxes, and image segmentation separates objects from backgrounds using binary masks, each serving specific roles in computer vision tasks. The choice of a specific approach depends on the task and the goal at hand.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
